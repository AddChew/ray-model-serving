import os
import logging

from ray import serve
from typing import Union, Dict, List
from fastapi import FastAPI, Body, Depends

from auth import verify_api_key
from schemas import BasePayload, DOBPayload, Prediction, Message


# TODO: think of how to manage the logs for different models, by right each model should have own logs, do in init?
# formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# fileHandler = logging.FileHandler('sentiment_analysis_model_api.log')
# fileHandler.setLevel(logging.INFO)
# fileHandler.setFormatter(formatter)

# logger = logging.getLogger('ray.serve')
# logger.addHandler(fileHandler)


app = FastAPI(
    title = 'Multiple Models Deployment',
    description = 'Documentation for multiple models deployment'
)


class FactoryModel:

    def __call__(self, payload: Union[BasePayload, DOBPayload]) -> List[Dict]:
        return [
            {'label': f'Label is generated by {payload.model}', 'score': 0.99} 
            for _ in payload.alerts
        ]


@serve.deployment(
    name = 'BaseModel',
    autoscaling_config = {
        'min_replicas': 1,
        'initial_replicas': 1,
        'max_replicas': 1,
        'target_num_ongoing_requests_per_replica': 10,
        'downscale_delay_s': 600,
        'upscale_delay_s': 30,        
    }
)
class BaseModel(FactoryModel):
    pass


@serve.deployment(
    name = 'CFSModel',
    autoscaling_config = {
        'min_replicas': 1,
        'initial_replicas': 1,
        'max_replicas': 1,
        'target_num_ongoing_requests_per_replica': 10,
        'downscale_delay_s': 600,
        'upscale_delay_s': 30,        
    }
)
class CFSModel(FactoryModel):
    pass


@serve.deployment(
    name = 'Driver',
    autoscaling_config = {
        'min_replicas': 1,
        'initial_replicas': 1,
        'max_replicas': 1,
        'target_num_ongoing_requests_per_replica': 10,
        'downscale_delay_s': 600,
        'upscale_delay_s': 30,        
    }
)
@serve.ingress(app)
class Driver:

    def __init__(self, base_model, cfs_model):
        # Code in __init__ will only run once in each replica on startup
        # Normally, will load the model here
        self._base_model = base_model
        self._cfs_model = cfs_model

    @app.post(
            path = '/model', 
            tags = ['Model Inference'], 
            summary = 'Model Inference on payload data',
            dependencies = [Depends(verify_api_key)],
            responses = {401: {'model': Message}}
    )
    async def predict(self, payload: Union[BasePayload, DOBPayload] = Body(discriminator = 'model')) -> List[Prediction]:
        """
        Model Inference on payload data.
        """
        if 'BASE' in payload.model:
            model = self._base_model

        elif 'CFS' in payload.model:
            model = self._cfs_model

        ref = await model.remote(payload)
        return await ref


base_model = BaseModel.bind()
cfs_model = CFSModel.bind()
driver = Driver.bind(base_model, cfs_model)